# Cython練習
## 動機
データの集計・可視化にPythonは便利だが、ビッグデータに対してはPure Pythonだと動作が遅すぎる。  
そこで、Cythonを導入して少しでも高速にデータ解析を進めたい。

<br>

## 実現したいこと
数百GBの気象データを可視化する。  
1時間ごとの地表面データが1年分ずつ格納されているバイナリファイル20個を順番に読み込んで加工し、最終的にグラフを出力する。  

<br>

## ディレクトリ構成
### tutorial
まずは`Hello World`をCythonで

### fibonacci
フィボナッチ数列の高速化

### file_io
ファイルの読み込みを含む関数の高速化  
→I/Oバウンドな処理なので高速化できず、むしろ遅い

### sample
サンプルデータでのデモ  


<br>

## 結論
複数回同じプログラムを実行する際にはCythonは有効な手段である。特にfor文の多いプログラムには有効。  
一方、ビッグデータ集計時のように一度きりしか実行しないプログラムやI/Oバウンドな処理に関しては高速化が見込めず、Cythonを使用するメリットが小さいため、他手法を検討する必要がある。また、演算にndarrayを使用したり、データ型を単精度にすることで高速化できることもわかった。

<br>

## 他手法
- アルゴリズムを工夫する  
  一番現実的な方法。今回はファイルのI/Oがボトルネックと考えられるので、ファイルを分割するのが良さそう。
- numba  
  手軽に高速化できるが、Cython同様のデメリットを持ち、一部対応していない部分もある。
- 並列処理(マルチプロセス、ProcessPoolExecutor)  
  計算量が多く分割して処理しても問題ないときに有効。今回はI/Oバウンドと考えられるので、効果は薄そう。
- 並行処理(マルチスレッド、ThreadPoolExecutor)  
  待ち時間が多いときに有効。